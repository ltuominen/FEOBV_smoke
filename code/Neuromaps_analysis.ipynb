{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from neuromaps.images import load_data, load_gifti, annot_to_gifti, relabel_gifti, construct_shape_gii\n",
    "from neuromaps.datasets import fetch_annotation\n",
    "from neuromaps.resampling import resample_images\n",
    "from neuromaps.nulls import alexander_bloch, burt2020\n",
    "from neuromaps.parcellate import Parcellater\n",
    "from scipy.stats import pearsonr\n",
    "from neuromaps import transforms \n",
    "from neuromaps.stats import compare_images\n",
    "from neuromaps.nulls import hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/Users/laurituominen/Documents/Research/FEOBV_smoke/parcellations/atlas-desikankilliany_space-fsaverage_den-10k_hemi-L.label.gii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nibabel/loadsave.py:100\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/laurituominen/Documents/Research/FEOBV_smoke/parcellations/atlas-desikankilliany_space-fsaverage_den-10k_hemi-L.label.gii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# load atlas \u001b[39;00m\n\u001b[1;32m     34\u001b[0m atlas \u001b[38;5;241m=\u001b[39m load_atlas(base_path)\n\u001b[0;32m---> 35\u001b[0m parcellater_fs10k, parcellater_fs164k, parcellater_mni \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_parcellaters\u001b[49m\u001b[43m(\u001b[49m\u001b[43matlas\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m, in \u001b[0;36mcreate_parcellaters\u001b[0;34m(atlas)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_parcellaters\u001b[39m(atlas):\n\u001b[0;32m---> 23\u001b[0m     dk_fsaverage_10k \u001b[38;5;241m=\u001b[39m \u001b[43mrelabel_gifti\u001b[49m\u001b[43m(\u001b[49m\u001b[43matlas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdk_fsaverage_10k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     parcellater_fs10k \u001b[38;5;241m=\u001b[39m Parcellater(dk_fsaverage_10k, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsaverage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m     dk_fsaverage_164k \u001b[38;5;241m=\u001b[39m annot_to_gifti(atlas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdk_fsaverage_164k\u001b[39m\u001b[38;5;124m'\u001b[39m])  \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/neuromaps/images.py:459\u001b[0m, in \u001b[0;36mrelabel_gifti\u001b[0;34m(parcellation, background, offset)\u001b[0m\n\u001b[1;32m    455\u001b[0m     background \u001b[38;5;241m=\u001b[39m PARCIGNORE\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hemi \u001b[38;5;129;01min\u001b[39;00m parcellation:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# get necessary info from file\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_gifti\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhemi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     data \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39magg_data()\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    461\u001b[0m     labels \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mlabeltable\u001b[38;5;241m.\u001b[39mlabels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/neuromaps/images.py:158\u001b[0m, in \u001b[0;36mload_gifti\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mLoad gifti file `img`.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Loaded GIFTI images\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ImageFileError, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# it's gzipped, so read the gzip and pipe it in\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, ImageFileError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gii.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nibabel/loadsave.py:102\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/Users/laurituominen/Documents/Research/FEOBV_smoke/parcellations/atlas-desikankilliany_space-fsaverage_den-10k_hemi-L.label.gii.gz'"
     ]
    }
   ],
   "source": [
    "# define path\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "def load_atlas(base_path):\n",
    "    \"\"\"\n",
    "    Load different parcellation files.\n",
    "    \"\"\"    \n",
    "    atlas= {\n",
    "        'dk_fsaverage_10k': (\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-10k_hemi-L.label.gii.gz'),\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-10k_hemi-R.label.gii.gz')\n",
    "    ),\n",
    "    'dk_fsaverage_164k': (\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-164k_hemi-L.aparc-1.annot'),\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-164k_hemi-R.aparc-1.annot')\n",
    "    ),\n",
    "    'dk_mni': os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-MNI_res-1mm.nii.gz')\n",
    "    }\n",
    "    return (atlas) \n",
    "\n",
    "# create parcellaters \n",
    "def create_parcellaters(atlas):\n",
    "    dk_fsaverage_10k = relabel_gifti(atlas['dk_fsaverage_10k'])\n",
    "    parcellater_fs10k = Parcellater(dk_fsaverage_10k, 'fsaverage')\n",
    "    \n",
    "    dk_fsaverage_164k = annot_to_gifti(atlas['dk_fsaverage_164k'])  \n",
    "    parcellater_fs164k = Parcellater(dk_fsaverage_164k, 'fsaverage')\n",
    "\n",
    "    parcellater_mni = Parcellater(atlas['dk_mni'], 'MNI152')\n",
    "    return (parcellater_fs10k, parcellater_fs164k, parcellater_mni) \n",
    "\n",
    "    \n",
    "# load atlas \n",
    "atlas = load_atlas(base_path)\n",
    "parcellater_fs10k, parcellater_fs164k, parcellater_mni = create_parcellaters(atlas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get turku & enigma data \n",
    "\n",
    "def parcellated_Turku(base_path):\n",
    "    # get turku maps  \n",
    "    img_L = load_data(os.path.join(base_path, 'data', 'lh.sig.nii'))\n",
    "    img_R = load_data(os.path.join(base_path, 'data', 'rh.sig.nii'))\n",
    "    turku_map = (construct_shape_gii(img_L), construct_shape_gii(img_R))\n",
    "\n",
    "    turku_parc = parcellater_fs164k.fit_transform(turku_map, space='fsaverage', ignore_background_data=True)\n",
    "    \n",
    "    return turku_parc \n",
    "    \n",
    "turku_parc = parcellated_Turku(base_path)\n",
    "np.save(os.path.join(base_path, 'data' 'turku_parc.npy'), turku_parc)\n",
    "\n",
    "# download enigma\n",
    "enigma_file='ENIGMA_S32_partial_correlation_between_cortical_thickness_and_chlorpromazine_equivalents.csv' \n",
    "enigmamap = pd.read_csv(os.path.join(base_path, 'data',enigma_file))\n",
    "enigmamap.drop([68, 69], inplace=True)  # Remove the last two rows\n",
    "enigma_parc = enigmamap['partial_r'].to_numpy()\n",
    "\n",
    "\n",
    "# download the regions for MNI152, take indecies of surface rois  \n",
    "rois = pd.read_csv(os.path.join(base_path, 'parcellations' ,'atlas-desikankilliany.csv'))\n",
    "rois = rois[(rois['structure'] == 'cortex')].index.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annotations \n",
    "annotations = list(fetch_annotation(source=['hcps1200',\n",
    "                                            'raichle',\n",
    "                                            'ding2010', \n",
    "                                            'finnema2016', \n",
    "                                            'dubois2015',\n",
    "                                            'gallezot2010',\n",
    "                                            'gallezot2017',\n",
    "                                            'hillmer2016',\n",
    "                                            'jaworska2020',\n",
    "                                            'kaller2017',\n",
    "                                            'kantonen2020',\n",
    "                                            'laurikainen2018',\n",
    "                                            'normandin2015',\n",
    "                                            'radnakrishnan2018',\n",
    "                                            'sandiego2015',\n",
    "                                            'satterthwaite2014',\n",
    "                                            'savli2012',\n",
    "                                            'satterthwaite2014',\n",
    "                                            'smith2017',\n",
    "                                            'tuominen',\n",
    "                                            'naganawa2020',\n",
    "                                            'fazio2016',\n",
    "                                            'vijay2018']).keys())\n",
    "\n",
    "annotations.extend(fetch_annotation(source=['norgaard2021', 'beliveau2017'], space='fsaverage').keys())\n",
    "annotations.extend(fetch_annotation(source='margulies2016', desc='fcgradient01', return_single=False).keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parcellater_mni' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m annot \u001b[38;5;241m=\u001b[39m fetch_annotation(source\u001b[38;5;241m=\u001b[39msrc, desc\u001b[38;5;241m=\u001b[39mdesc, space\u001b[38;5;241m=\u001b[39mspace, den\u001b[38;5;241m=\u001b[39mden)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m space \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNI152\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     parcellater \u001b[38;5;241m=\u001b[39m \u001b[43mparcellater_mni\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m space \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsaverage\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m den \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m164k\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     14\u001b[0m     parcellater \u001b[38;5;241m=\u001b[39m parcellater_fs164k\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parcellater_mni' is not defined"
     ]
    }
   ],
   "source": [
    "# parcellate annotations\n",
    "\n",
    "# initialize\n",
    "parcellated = dict([])\n",
    "\n",
    "# go over each annotation and parcellate depending on the space \n",
    "for (src, desc, space, den) in annotations:\n",
    "\n",
    "    annot = fetch_annotation(source=src, desc=desc, space=space, den=den)\n",
    "    \n",
    "    if space == 'MNI152':\n",
    "        parcellater = parcellater_mni\n",
    "    elif space == 'fsaverage' and den == '164k':\n",
    "        parcellater = parcellater_fs164k\n",
    "    elif space == 'fsLR' and den == '164k':\n",
    "        space = 'fsaverage'\n",
    "        annot = transforms.fslr_to_fsaverage(annot, target_density='164k')\n",
    "        parcellater = parcellater_fs164k\n",
    "    elif space == 'fsLR' and den != '164k':\n",
    "        # unfortunately for fsLR-4k we are upsampling to fsaverage-10k to parcellate but it should be fine\n",
    "        space = 'fsaverage'\n",
    "        annot = transforms.fslr_to_fsaverage(annot, target_density='10k')\n",
    "        parcellater = parcellater_fs10k\n",
    "\n",
    "    parcellated[desc] = parcellater.fit_transform(annot, space=space, ignore_background_data=True)\n",
    "\n",
    "    # if subcortex included remove \n",
    "    if parcellated[desc].shape == (1,83):\n",
    "        parcellated[desc] = parcellated[desc][0][rois]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spins \n",
    "spins = pd.read_csv(os.path.join(base_path, 'parcellations', \n",
    "                                 'spins_hungarian_aparc+aseg_ctx.csv'), header=None)\n",
    "nspins = spins.values.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corrs(annotations, parc):\n",
    "    \"\"\"\n",
    "    Calculate correlations & nulls between parcellated annotations & \n",
    "    parcellated antipsychotic effects on cortical thickness \n",
    "    \"\"\"\n",
    "\n",
    "    # initialize\n",
    "    nulls = dict([])\n",
    "    corrs = dict([])\n",
    "    \n",
    "    # go over annotations \n",
    "    for src, desc, space, den in annotations:\n",
    "        if space == 'MNI152':\n",
    "            parcellation=atlas['dk_mni']\n",
    "            \n",
    "        elif space == 'fsaverage' and den == '164k':\n",
    "            parcellation=atlas['dk_fsaverage_164k']\n",
    "            \n",
    "        elif space == 'fsLR' and den == '164k':\n",
    "            parcellation=atlas['dk_fsaverage_164k']\n",
    "            \n",
    "        elif space == 'fsLR' and den != '164k':\n",
    "            parcellation=atlas['dk_fsaverage_10k']\n",
    "        \n",
    "        # empirical correlation between annotations and parc\n",
    "        rho = pearsonr(parcellated[desc], parc)[0]\n",
    "        \n",
    "        # get 10k rotations \n",
    "        rotated = hungarian(data=parcellated[desc], n_perm=10000, spins=spins, parcellation=parcellation) \n",
    "        \n",
    "        # get null \n",
    "        n = np.zeros((nspins, ))\n",
    "        for i in range(nspins):\n",
    "            n[i] = pearsonr(parc, rotated[:,i])[0]    \n",
    "        \n",
    "        # get p-value\n",
    "        pspin = (1 + sum(abs(n) > abs(rho ))) / (nspins + 1)\n",
    "    \n",
    "        # store, multiply by -1 to make more intuitive, because smaller p-value/rho means bigger effect  \n",
    "        corrs[src+'_'+desc] = ( (-1 * rho, pspin ) )\n",
    "        nulls[src+'_'+desc] = n\n",
    "        \n",
    "    return(nulls, corrs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_turku, corrs_turku = calc_corrs(annotations, turku_parc)\n",
    "nulls_enigma, corrs_enigma = calc_corrs(annotations, enigma_parc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save correlations & nulls \n",
    "np.savez(os.path.join(base_path, 'data', 'corrs_turku.npz'), **corrs_turku)\n",
    "np.savez(os.path.join(base_path, 'data', 'nulls_turku.npz'), **nulls_turku)\n",
    "np.savez(os.path.join(base_path, 'data', 'nulls_enigma.npz'), **nulls_enigma)\n",
    "np.savez(os.path.join(base_path, 'data', 'corrs_enigma.npz'), **corrs_enigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
