{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from neuromaps.images import load_data, load_gifti, annot_to_gifti, relabel_gifti, construct_shape_gii\n",
    "from neuromaps.datasets import fetch_annotation\n",
    "from neuromaps.resampling import resample_images\n",
    "from neuromaps.nulls import alexander_bloch, burt2020\n",
    "from neuromaps.parcellate import Parcellater\n",
    "from scipy.stats import pearsonr\n",
    "from neuromaps import transforms \n",
    "from neuromaps.stats import compare_images\n",
    "from neuromaps.nulls import hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "def load_atlas(base_path):\n",
    "    \"\"\"\n",
    "    Load different parcellation files.\n",
    "    \"\"\"    \n",
    "    atlas= {\n",
    "        'dk_fsaverage_10k': (\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-10k_hemi-L.label.gii.gz'),\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-10k_hemi-R.label.gii.gz')\n",
    "    ),\n",
    "    'dk_fsaverage_164k': (\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-164k_hemi-L.aparc-1.annot'),\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-164k_hemi-R.aparc-1.annot')\n",
    "    ),\n",
    "    'dk_mni': os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-MNI_res-1mm.nii.gz')\n",
    "    }\n",
    "    return (atlas) \n",
    "\n",
    "# create parcellaters \n",
    "def create_parcellaters(atlas):\n",
    "    dk_fsaverage_10k = relabel_gifti(atlas['dk_fsaverage_10k'])\n",
    "    parcellater_fs10k = Parcellater(dk_fsaverage_10k, 'fsaverage')\n",
    "    \n",
    "    dk_fsaverage_164k = annot_to_gifti(atlas['dk_fsaverage_164k'])  \n",
    "    parcellater_fs164k = Parcellater(dk_fsaverage_164k, 'fsaverage')\n",
    "\n",
    "    parcellater_mni = Parcellater(atlas['dk_mni'], 'MNI152')\n",
    "    return (parcellater_fs10k, parcellater_fs164k, parcellater_mni) \n",
    "\n",
    "    \n",
    "# load atlas \n",
    "atlas = load_atlas(base_path)\n",
    "parcellater_fs10k, parcellater_fs164k, parcellater_mni = create_parcellaters(atlas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get turku & enigma data \n",
    "\n",
    "def parcellated_Turku(base_path):\n",
    "    # get turku maps  \n",
    "    img_L = load_data(os.path.join(base_path, 'data', 'lh.sig.nii'))\n",
    "    img_R = load_data(os.path.join(base_path, 'data', 'rh.sig.nii'))\n",
    "    turku_map = (construct_shape_gii(img_L), construct_shape_gii(img_R))\n",
    "\n",
    "    turku_parc = parcellater_fs164k.fit_transform(turku_map, space='fsaverage', ignore_background_data=True)\n",
    "    \n",
    "    return turku_parc \n",
    "    \n",
    "turku_parc = parcellated_Turku(base_path)\n",
    "np.save(os.path.join(base_path, 'data' 'turku_parc.npy'), turku_parc)\n",
    "\n",
    "# download enigma\n",
    "enigma_file='ENIGMA_S32_partial_correlation_between_cortical_thickness_and_chlorpromazine_equivalents.csv' \n",
    "enigmamap = pd.read_csv(os.path.join(base_path, 'data',enigma_file))\n",
    "enigmamap.drop([68, 69], inplace=True)  # Remove the last two rows\n",
    "enigma_parc = enigmamap['partial_r'].to_numpy()\n",
    "\n",
    "\n",
    "# download the regions for MNI152, take indecies of surface rois  \n",
    "rois = pd.read_csv(os.path.join(base_path, 'parcellations' ,'atlas-desikankilliany.csv'))\n",
    "rois = rois[(rois['structure'] == 'cortex')].index.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annotations \n",
    "annotations = list(fetch_annotation(source=['hcps1200',\n",
    "                                            'raichle',\n",
    "                                            'ding2010', \n",
    "                                            'finnema2016', \n",
    "                                            'dubois2015',\n",
    "                                            'gallezot2010',\n",
    "                                            'gallezot2017',\n",
    "                                            'hillmer2016',\n",
    "                                            'jaworska2020',\n",
    "                                            'kaller2017',\n",
    "                                            'kantonen2020',\n",
    "                                            'laurikainen2018',\n",
    "                                            'normandin2015',\n",
    "                                            'radnakrishnan2018',\n",
    "                                            'sandiego2015',\n",
    "                                            'satterthwaite2014',\n",
    "                                            'savli2012',\n",
    "                                            'satterthwaite2014',\n",
    "                                            'smith2017',\n",
    "                                            'tuominen',\n",
    "                                            'naganawa2020',\n",
    "                                            'fazio2016',\n",
    "                                            'vijay2018']).keys())\n",
    "\n",
    "annotations.extend(fetch_annotation(source=['norgaard2021', 'beliveau2017'], space='fsaverage').keys())\n",
    "annotations.extend(fetch_annotation(source='margulies2016', desc='fcgradient01', return_single=False).keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SubprocessError",
     "evalue": "Command failed with non-zero exit status 127. Error traceback: \"/bin/sh: wb_command: command not found\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/neuromaps/utils.py:78\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(cmd, env, return_proc, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'wb_command -metric-resample /Users/laurituominen/neuromaps-data/annotations/hcps1200/megalpha/fsLR/source-hcps1200_desc-megalpha_space-fsLR_den-4k_hemi-L_feature.func.gii /Users/laurituominen/neuromaps-data/atlases/fsLR/tpl-fsLR_space-fsaverage_den-4k_hemi-L_sphere.surf.gii /Users/laurituominen/neuromaps-data/atlases/fsaverage/tpl-fsaverage_den-10k_hemi-L_sphere.surf.gii ADAP_BARY_AREA /var/folders/ft/yby1tt_573g4_h62k4ny40d00000gn/T/tmpnxk3gkmc.func.gii -area-metrics /Users/laurituominen/neuromaps-data/atlases/fsLR/tpl-fsLR_den-4k_hemi-L_desc-vaavg_midthickness.shape.gii /Users/laurituominen/neuromaps-data/atlases/fsaverage/tpl-fsaverage_den-10k_hemi-L_desc-vaavg_midthickness.shape.gii -current-roi /Users/laurituominen/neuromaps-data/atlases/fsLR/tpl-fsLR_den-4k_hemi-L_desc-nomedialwall_dparc.label.gii' returned non-zero exit status 127.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSubprocessError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m space \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsLR\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m den \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m164k\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# unfortunately for fsLR-4k we are upsampling to fsaverage-10k to parcellate but it should be fine\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     space \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsaverage\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 22\u001b[0m     annot \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfslr_to_fsaverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_density\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     parcellater \u001b[38;5;241m=\u001b[39m parcellater_fs10k\n\u001b[1;32m     25\u001b[0m parcellated[desc] \u001b[38;5;241m=\u001b[39m parcellater\u001b[38;5;241m.\u001b[39mfit_transform(annot, space\u001b[38;5;241m=\u001b[39mspace, ignore_background_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/neuromaps/transforms.py:508\u001b[0m, in \u001b[0;36mfslr_to_fsaverage\u001b[0;34m(data, target_density, hemi, method)\u001b[0m\n\u001b[1;32m    506\u001b[0m srcparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(space\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsLR\u001b[39m\u001b[38;5;124m'\u001b[39m, den\u001b[38;5;241m=\u001b[39mdensity, trg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_space-fsaverage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    507\u001b[0m trgparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(space\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsaverage\u001b[39m\u001b[38;5;124m'\u001b[39m, den\u001b[38;5;241m=\u001b[39mtarget_density, trg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_surf_to_surf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrcparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrgparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhemi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/neuromaps/transforms.py:362\u001b[0m, in \u001b[0;36m_surf_to_surf\u001b[0;34m(data, srcparams, trgparams, method, hemi)\u001b[0m\n\u001b[1;32m    351\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    352\u001b[0m     metric\u001b[38;5;241m=\u001b[39mimg,\n\u001b[1;32m    353\u001b[0m     out\u001b[38;5;241m=\u001b[39mtmpname(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.func.gii\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m     trgmask\u001b[38;5;241m=\u001b[39mtrgdir \u001b[38;5;241m/\u001b[39m MLFMT\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrgparams)\n\u001b[1;32m    360\u001b[0m )\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m (func, MASKSURF):\n\u001b[0;32m--> 362\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m resampled \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (construct_shape_gii(load_data(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m])),)\n\u001b[1;32m    364\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munlink()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/neuromaps/utils.py:80\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(cmd, env, return_proc, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     proc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, env\u001b[38;5;241m=\u001b[39mmerged_env, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mSubprocessError(\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCommand failed with non-zero exit status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39mreturncode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError traceback: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     83\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_proc:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proc\n",
      "\u001b[0;31mSubprocessError\u001b[0m: Command failed with non-zero exit status 127. Error traceback: \"/bin/sh: wb_command: command not found\""
     ]
    }
   ],
   "source": [
    "# parcellate annotations\n",
    "\n",
    "# initialize\n",
    "parcellated = dict([])\n",
    "\n",
    "# go over each annotation and parcellate depending on the space \n",
    "for (src, desc, space, den) in annotations:\n",
    "\n",
    "    annot = fetch_annotation(source=src, desc=desc, space=space, den=den)\n",
    "    \n",
    "    if space == 'MNI152':\n",
    "        parcellater = parcellater_mni\n",
    "    elif space == 'fsaverage' and den == '164k':\n",
    "        parcellater = parcellater_fs164k\n",
    "    elif space == 'fsLR' and den == '164k':\n",
    "        space = 'fsaverage'\n",
    "        annot = transforms.fslr_to_fsaverage(annot, target_density='164k')\n",
    "        parcellater = parcellater_fs164k\n",
    "    elif space == 'fsLR' and den != '164k':\n",
    "        # unfortunately for fsLR-4k we are upsampling to fsaverage-10k to parcellate but it should be fine\n",
    "        space = 'fsaverage'\n",
    "        annot = transforms.fslr_to_fsaverage(annot, target_density='10k')\n",
    "        parcellater = parcellater_fs10k\n",
    "\n",
    "    parcellated[desc] = parcellater.fit_transform(annot, space=space, ignore_background_data=True)\n",
    "\n",
    "    # if subcortex included remove \n",
    "    if parcellated[desc].shape == (1,83):\n",
    "        parcellated[desc] = parcellated[desc][0][rois]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spins \n",
    "spins = pd.read_csv(os.path.join(base_path, 'parcellations', \n",
    "                                 'spins_hungarian_aparc+aseg_ctx.csv'), header=None)\n",
    "nspins = spins.values.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corrs(annotations, parc):\n",
    "    \"\"\"\n",
    "    Calculate correlations & nulls between parcellated annotations & \n",
    "    parcellated antipsychotic effects on cortical thickness \n",
    "    \"\"\"\n",
    "\n",
    "    # initialize\n",
    "    nulls = dict([])\n",
    "    corrs = dict([])\n",
    "    \n",
    "    # go over annotations \n",
    "    for src, desc, space, den in annotations:\n",
    "        if space == 'MNI152':\n",
    "            parcellation=atlas['dk_mni']\n",
    "            \n",
    "        elif space == 'fsaverage' and den == '164k':\n",
    "            parcellation=atlas['dk_fsaverage_164k']\n",
    "            \n",
    "        elif space == 'fsLR' and den == '164k':\n",
    "            parcellation=atlas['dk_fsaverage_164k']\n",
    "            \n",
    "        elif space == 'fsLR' and den != '164k':\n",
    "            parcellation=atlas['dk_fsaverage_10k']\n",
    "        \n",
    "        # empirical correlation between annotations and parc\n",
    "        rho = pearsonr(parcellated[desc], parc)[0]\n",
    "        \n",
    "        # get 10k rotations \n",
    "        rotated = hungarian(data=parcellated[desc], n_perm=10000, spins=spins, parcellation=parcellation) \n",
    "        \n",
    "        # get null \n",
    "        n = np.zeros((nspins, ))\n",
    "        for i in range(nspins):\n",
    "            n[i] = pearsonr(parc, rotated[:,i])[0]    \n",
    "        \n",
    "        # get p-value\n",
    "        pspin = (1 + sum(abs(n) > abs(rho ))) / (nspins + 1)\n",
    "    \n",
    "        # store, multiply by -1 to make more intuitive, because smaller p-value/rho means bigger effect  \n",
    "        corrs[src+'_'+desc] = ( (-1 * rho, pspin ) )\n",
    "        nulls[src+'_'+desc] = n\n",
    "        \n",
    "    return(nulls, corrs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_turku, corrs_turku = calc_corrs(annotations, turku_parc)\n",
    "nulls_enigma, corrs_enigma = calc_corrs(annotations, enigma_parc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save correlations & nulls \n",
    "np.savez(os.path.join(base_path, 'data', 'corrs_turku.npz'), **corrs_turku)\n",
    "np.savez(os.path.join(base_path, 'data', 'nulls_turku.npz'), **nulls_turku)\n",
    "np.savez(os.path.join(base_path, 'data', 'nulls_enigma.npz'), **nulls_enigma)\n",
    "np.savez(os.path.join(base_path, 'data', 'corrs_enigma.npz'), **corrs_enigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
